"""Central scoring engine for IRIS.

Classifies URLs into a 3-tier system (Safe / Uncertain / Malicious) with a
confidence percentage that reflects how strongly the evidence agrees on the
classification.  Threat feed matches are treated as weighted signals — not
binary overrides — so a single low-confidence hit is distinguished from
unanimous feed agreement.
"""

from __future__ import annotations

from typing import Any

from iris.models import AnalyzerResult, AnalyzerStatus, FeedResult, RiskCategory

# Default per-feed weights used when config does not specify them.
_DEFAULT_FEED_WEIGHTS: dict[str, float] = {
    "VirusTotal": 40.0,
    "Google Safe Browsing": 35.0,
    "AbuseIPDB": 25.0,
}


def calculate_score(
    results: list[AnalyzerResult],
    feed_results: list[FeedResult],
    config: dict[str, Any],
) -> tuple[float, RiskCategory, float]:
    """Aggregate analyzer results into a classification and confidence.

    The pipeline is:
      1. Weighted average of completed analyzer scores (0-100).
      2. Graduated feed signal (0-100) based on which feeds matched.
      3. Composite score blending analyzers and feeds.
      4. 3-tier classification via configurable thresholds.
      5. Confidence percentage reflecting signal agreement.

    Args:
        results: List of AnalyzerResult from all analyzers.
        feed_results: List of FeedResult from threat feed checks.
        config: The loaded configuration dictionary.

    Returns:
        Tuple of (composite_score, risk_category, confidence_pct).
    """
    completed = [r for r in results if r.status == AnalyzerStatus.COMPLETED]

    if not completed:
        has_match = any(fr.matched for fr in feed_results)
        if has_match:
            return 100.0, RiskCategory.MALICIOUS, 60.0
        return 0.0, RiskCategory.SAFE, 50.0

    # ------------------------------------------------------------------
    # Step 1: Raw weighted analyzer score
    # ------------------------------------------------------------------
    total_weight = sum(r.max_weight for r in completed)
    raw_score = 0.0
    for result in completed:
        normalized_weight = result.max_weight / total_weight
        raw_score += result.score * normalized_weight

    # ------------------------------------------------------------------
    # Step 2: Graduated feed signal
    # ------------------------------------------------------------------
    feed_signal = _compute_feed_signal(feed_results, config)

    # ------------------------------------------------------------------
    # Step 3: Composite score (blend analyzers + feeds)
    # ------------------------------------------------------------------
    scoring_cfg = config.get("scoring", {})
    blend = scoring_cfg.get("blend", {})
    analyzer_blend = blend.get("analyzer_weight", 0.45)
    feed_blend = blend.get("feed_weight", 0.55)

    # If no feeds are configured at all, give all weight to analyzers.
    has_any_feed_configured = len(feed_results) > 0
    if not has_any_feed_configured:
        analyzer_blend = 1.0
        feed_blend = 0.0

    composite = (raw_score * analyzer_blend) + (feed_signal * feed_blend)
    composite = min(100.0, max(0.0, composite))

    # ------------------------------------------------------------------
    # Step 3b: High-confidence feed floor
    # ------------------------------------------------------------------
    # When a threat feed has strong detections (e.g. VT 10+ engines),
    # the composite should never fall into the "Safe" zone.  New phishing
    # campaigns are often flagged by VT well before GSB or AbuseIPDB
    # index them, so a strong single-feed signal is sufficient evidence.
    composite = _apply_feed_floor(composite, feed_results, config)

    # ------------------------------------------------------------------
    # Step 4: 3-tier classification
    # ------------------------------------------------------------------
    thresholds = scoring_cfg.get("thresholds", {})
    safe_max = thresholds.get("safe", 25)
    malicious_min = thresholds.get("malicious", 60)

    if composite <= safe_max:
        category = RiskCategory.SAFE
    elif composite >= malicious_min:
        category = RiskCategory.MALICIOUS
    else:
        category = RiskCategory.UNCERTAIN

    # ------------------------------------------------------------------
    # Step 5: Confidence percentage
    # ------------------------------------------------------------------
    confidence = _calculate_confidence(
        completed, composite, feed_signal, category, thresholds,
    )

    return round(composite, 1), category, confidence


def _compute_feed_signal(
    feed_results: list[FeedResult],
    config: dict[str, Any],
) -> float:
    """Compute a 0-100 feed signal with severity-aware scaling.

    The signal accounts for:
      - Which feeds matched (weighted by reliability).
      - How many VT engines flagged the URL (severity scaling).
      - Non-matching feeds only dilute the signal partially — absence
        of data in GSB/AbuseIPDB should not cancel a strong VT hit.

    Args:
        feed_results: List of FeedResult from threat feed checks.
        config: The loaded configuration dictionary.

    Returns:
        Feed signal strength on a 0-100 scale.
    """
    configured_weights = (
        config.get("scoring", {}).get("feed_weights", _DEFAULT_FEED_WEIGHTS)
    )

    total_feed_weight = 0.0
    matched_feed_weight = 0.0
    vt_severity_boost = 0.0

    for fr in feed_results:
        w = configured_weights.get(fr.feed_name, 30.0)
        total_feed_weight += w
        if fr.matched:
            matched_feed_weight += w

            # VirusTotal severity scaling: more detections = stronger signal
            if fr.feed_name == "VirusTotal" and fr.raw_response:
                malicious = fr.raw_response.get("malicious", 0)
                suspicious = fr.raw_response.get("suspicious", 0)
                detections = malicious + suspicious

                # Scale: 3-5 detections = mild boost, 10+ = strong, 20+ = maximum
                if detections >= 20:
                    vt_severity_boost = 50.0
                elif detections >= 10:
                    vt_severity_boost = 40.0
                elif detections >= 5:
                    vt_severity_boost = 25.0
                elif detections >= 3:
                    vt_severity_boost = 10.0

    if total_feed_weight <= 0:
        return 0.0

    base_signal = (matched_feed_weight / total_feed_weight) * 100.0

    # Combine: base signal + VT severity boost, capped at 100
    return min(100.0, base_signal + vt_severity_boost)


def _apply_feed_floor(
    composite: float,
    feed_results: list[FeedResult],
    config: dict[str, Any],
) -> float:
    """Enforce a minimum composite score when a feed has strong detections.

    New phishing campaigns are typically flagged by VirusTotal long before
    Google Safe Browsing or AbuseIPDB index them.  Without a floor, the
    absence of data from those feeds dilutes the VT signal enough to push
    clearly malicious URLs into the "Safe" zone.

    Floors (based on VT detection count):
      - 20+ detections → composite floor 75 (Malicious)
      - 10+ detections → composite floor 65 (Malicious)
      - 5+  detections → composite floor 40 (Uncertain)
      - 3+  detections → composite floor 30 (Uncertain)

    Args:
        composite: The current composite score.
        feed_results: List of FeedResult from threat feed checks.
        config: The loaded configuration dictionary.

    Returns:
        The composite score, raised to the floor if applicable.
    """
    for fr in feed_results:
        if fr.feed_name == "VirusTotal" and fr.matched and fr.raw_response:
            malicious = fr.raw_response.get("malicious", 0)
            suspicious = fr.raw_response.get("suspicious", 0)
            detections = malicious + suspicious

            if detections >= 20:
                composite = max(composite, 75.0)
            elif detections >= 10:
                composite = max(composite, 65.0)
            elif detections >= 5:
                composite = max(composite, 40.0)
            elif detections >= 3:
                composite = max(composite, 30.0)
            break

    return composite


def _calculate_confidence(
    completed: list[AnalyzerResult],
    composite_score: float,
    feed_signal: float,
    category: RiskCategory,
    thresholds: dict[str, Any],
) -> float:
    """Calculate confidence as a percentage.

    Designed for SOC analysts who need an instant read:
      - **Malicious** → 100%.  If the scoring engine classified it as
        malicious (VT detections, feed matches, etc.) the evidence is
        conclusive and confidence should reflect that.
      - **Safe** → 100%.  All signals agree there's no threat.
      - **Uncertain** → scales between 30-80% based on how far the
        composite is from the decision boundaries.  Low VT hits or
        ambiguous signals produce lower confidence.

    Args:
        completed: List of completed AnalyzerResults.
        composite_score: The blended composite score.
        feed_signal: Feed signal strength (0-100).
        category: The assigned RiskCategory.
        thresholds: Threshold config dict with 'safe' and 'malicious' keys.

    Returns:
        Confidence percentage rounded to 1 decimal.
    """
    if category == RiskCategory.MALICIOUS:
        return 100.0

    if category == RiskCategory.SAFE:
        return 100.0

    # --- UNCERTAIN zone: scale 30-80% based on evidence strength ---
    safe_max = thresholds.get("safe", 25)
    malicious_min = thresholds.get("malicious", 60)

    # How far into the uncertain zone (0.0 = near safe, 1.0 = near malicious)
    span = max(malicious_min - safe_max, 1)
    position = (composite_score - safe_max) / span
    position = min(1.0, max(0.0, position))

    # Near the boundaries = higher confidence in the *direction*;
    # mid-zone = lowest confidence (most ambiguous)
    # U-shaped curve: confidence is higher at edges, lower in middle
    distance_from_mid = abs(position - 0.5) * 2.0  # 0 at center, 1 at edges
    confidence = 30.0 + distance_from_mid * 50.0

    return round(min(80.0, max(30.0, confidence)), 1)
